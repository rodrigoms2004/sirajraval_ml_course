{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python for NLP: Vocabulary and Phrase Matching with SpaCy\n",
    "https://stackabuse.com/python-for-nlp-vocabulary-and-phrase-matching-with-spacy/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Matcher Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "m_tool = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = [{'LOWER': 'quickbrownfox'}]\n",
    "p2 = [{'LOWER': 'quick'}, {'IS_PUNCT': True}, {'LOWER': 'brown'}, {'IS_PUNCT': True}, {'LOWER': 'fox'}]\n",
    "p3 = [{'LOWER': 'quick'}, {'LOWER': 'brown'}, {'LOWER': 'fox'}]\n",
    "p4 =  [{'LOWER': 'quick'}, {'LOWER': 'brownfox'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* p1 looks for the phrase \"quickbrownfox\"\n",
    "* p2 looks for the phrase \"quick-brown-fox\"\n",
    "* p3 tries to search for \"qucik brown fox\"\n",
    "* p4 looks for the phrase \"quick brownfox\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the patterns are defined, we need to add them to the Matcher object that we created earlier.\n",
    "m_tool.add('QBF', None, p1, p2, p3, p4)\n",
    "# Here \"QBF\" is the name of our matcher. You can give it any name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Matcher to the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = nlp(u'The quick-brown-fox jumps over the lazy dog. The quick brown fox eats well. \\\n",
    "               the quickbrownfox is dead. the dog misses the quick brownfox')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12825528024649263697, 1, 6), (12825528024649263697, 13, 16), (12825528024649263697, 21, 22), (12825528024649263697, 29, 31)]\n"
     ]
    }
   ],
   "source": [
    "phrase_matches = m_tool(sentence)\n",
    "print(phrase_matches )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12825528024649263697 QBF 1 6 quick-brown-fox\n",
      "12825528024649263697 QBF 13 16 quick brown fox\n",
      "12825528024649263697 QBF 21 22 quickbrownfox\n",
      "12825528024649263697 QBF 29 31 quick brownfox\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in phrase_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  \n",
    "    span = sentence[start:end]                   \n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tool.remove('QBF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = [{'LOWER': 'quick'}, {'IS_PUNCT': True, 'OP':'*'}, {'LOWER': 'brown'}, {'IS_PUNCT': True, 'OP':'*'}, {'LOWER': 'fox'}]\n",
    "m_tool.add('QBF', None, p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = nlp(u'The quick--brown--fox jumps over the  quick-brown---fox')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12825528024649263697 QBF 1 6 quick--brown--fox\n",
      "12825528024649263697 QBF 10 15 quick-brown---fox\n"
     ]
    }
   ],
   "source": [
    "phrase_matches = m_tool(sentence)\n",
    "\n",
    "for match_id, start, end in phrase_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  \n",
    "    span = sentence[start:end]                   \n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase-Based Matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs  \n",
    "import urllib.request  \n",
    "import re  \n",
    "import nltk\n",
    "\n",
    "scrapped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Artificial_intelligence')  \n",
    "article = scrapped_data .read()\n",
    "\n",
    "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
    "\n",
    "paragraphs = parsed_article.find_all('p')\n",
    "\n",
    "article_text = \"\"\n",
    "\n",
    "for p in paragraphs:  \n",
    "    article_text += p.text\n",
    "    \n",
    "    \n",
    "processed_article = article_text.lower()  \n",
    "processed_article = re.sub('[^a-zA-Z]', ' ', processed_article )  \n",
    "processed_article = re.sub(r'\\s+', ' ', processed_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Phrase Matcher Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "from spacy.matcher import PhraseMatcher\n",
    "phrase_matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Phrase List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = ['machine learning', 'robots', 'intelligent agents']\n",
    "\n",
    "patterns = [nlp(text) for text in phrases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_matcher.add('AI', None, *patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Matcher to the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5530044837203964789, 35, 37),\n",
       " (5530044837203964789, 350, 352),\n",
       " (5530044837203964789, 641, 642),\n",
       " (5530044837203964789, 1233, 1235),\n",
       " (5530044837203964789, 1548, 1550),\n",
       " (5530044837203964789, 3094, 3096),\n",
       " (5530044837203964789, 3253, 3255),\n",
       " (5530044837203964789, 3793, 3794),\n",
       " (5530044837203964789, 5251, 5252),\n",
       " (5530044837203964789, 5328, 5329),\n",
       " (5530044837203964789, 6816, 6818),\n",
       " (5530044837203964789, 6828, 6830),\n",
       " (5530044837203964789, 7550, 7552),\n",
       " (5530044837203964789, 7689, 7691),\n",
       " (5530044837203964789, 8056, 8058),\n",
       " (5530044837203964789, 9531, 9532),\n",
       " (5530044837203964789, 9596, 9597),\n",
       " (5530044837203964789, 9851, 9853),\n",
       " (5530044837203964789, 10203, 10205),\n",
       " (5530044837203964789, 11231, 11232),\n",
       " (5530044837203964789, 11697, 11698),\n",
       " (5530044837203964789, 12711, 12712),\n",
       " (5530044837203964789, 12822, 12823),\n",
       " (5530044837203964789, 12943, 12944),\n",
       " (5530044837203964789, 12987, 12988)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = nlp (processed_article)\n",
    "\n",
    "matched_phrases = phrase_matcher(sentence)\n",
    "matched_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5530044837203964789 AI 35 37 intelligent agents\n",
      "5530044837203964789 AI 350 352 machine learning\n",
      "5530044837203964789 AI 641 642 robots\n",
      "5530044837203964789 AI 1233 1235 machine learning\n",
      "5530044837203964789 AI 1548 1550 intelligent agents\n",
      "5530044837203964789 AI 3094 3096 intelligent agents\n",
      "5530044837203964789 AI 3253 3255 machine learning\n",
      "5530044837203964789 AI 3793 3794 robots\n",
      "5530044837203964789 AI 5251 5252 robots\n",
      "5530044837203964789 AI 5328 5329 robots\n",
      "5530044837203964789 AI 6816 6818 machine learning\n",
      "5530044837203964789 AI 6828 6830 machine learning\n",
      "5530044837203964789 AI 7550 7552 machine learning\n",
      "5530044837203964789 AI 7689 7691 machine learning\n",
      "5530044837203964789 AI 8056 8058 machine learning\n",
      "5530044837203964789 AI 9531 9532 robots\n",
      "5530044837203964789 AI 9596 9597 robots\n",
      "5530044837203964789 AI 9851 9853 machine learning\n",
      "5530044837203964789 AI 10203 10205 machine learning\n",
      "5530044837203964789 AI 11231 11232 robots\n",
      "5530044837203964789 AI 11697 11698 robots\n",
      "5530044837203964789 AI 12711 12712 robots\n",
      "5530044837203964789 AI 12822 12823 robots\n",
      "5530044837203964789 AI 12943 12944 robots\n",
      "5530044837203964789 AI 12987 12988 robots\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matched_phrases:\n",
    "    string_id = nlp.vocab.strings[match_id]  \n",
    "    span = sentence[start:end]                   \n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'somehow', 'though', 'that', 'above', 'below', 'name', 'against', 'everywhere', 'few', 'part', 'someone', 'down', 'has', 'have', 'why', 'themselves', 'give', 'due', 'us', 'is', 'others', 'show', 'while', 'from', 'we', 'thereby', 'twelve', 'another', 'or', '’d', 'amongst', 'either', 'own', 'a', 'sometimes', 'whereby', 'many', \"'m\", 'became', 'besides', 'most', 'therein', 'seemed', 'ours', 'some', 'made', 'every', 'whoever', 'back', 'becomes', 'forty', 'he', 'once', 'no', 'take', 'across', 'therefore', 'which', 'latter', 'where', \"'ve\", 'whom', 'about', 'hereafter', 'except', 'last', 'and', 'through', 'onto', 'she', 'somewhere', 'whereas', 'not', '’ll', 'whole', 'me', 'next', 'whither', 'am', 'anywhere', 'during', 'front', 'my', 'mostly', 'i', 'four', 'mine', 'seeming', 'never', 'seems', 'thru', 'whence', 'with', 'everyone', 'although', 'eight', 'nor', 'her', 'these', 'throughout', 'what', 'amount', 'per', 'who', 'such', 'go', 'can', 'move', 'being', 'else', 'get', 'other', 'eleven', 'without', 'his', 'before', 'among', 'noone', 'say', 'wherever', 'thereupon', 'in', 'three', 'were', 'former', 'full', 'hereupon', 'should', 'behind', 'fifty', 'please', 'fifteen', 'because', 'seem', 'serious', 'off', 'together', 'anyway', 'anyhow', 'him', 'itself', 'now', 'any', 'ca', 'less', 'this', 'towards', '‘ll', 'anyone', 'nine', 'sometime', 'beyond', 'cannot', 'five', 'all', 'empty', 'almost', 'under', 'really', '‘s', 'more', 'n’t', 'been', 'doing', 'further', 'however', 'they', 'both', 'unless', 'those', '’s', 'indeed', 'afterwards', 'anything', 'become', 'first', 'hers', 'one', 'whatever', 'whether', '’m', 'whose', 'herself', 'upon', 'could', 'twenty', 'within', 'namely', 'does', 'ten', 'to', 'enough', '‘d', 'herein', 'just', 'then', 'least', 'moreover', 'via', 'put', 'over', 'nowhere', 'hence', 'several', 'there', 'yet', \"'ll\", 'you', 'for', 'using', 'myself', 'various', 'ever', 'along', 'always', 'call', 'two', 'used', 'them', 'beside', 'formerly', 'after', 'our', 'already', 'each', 'often', 'out', 'thus', \"'re\", '‘re', '‘ve', 'quite', 'was', 'also', 'only', 'nevertheless', 'might', 'whereafter', 'wherein', 'bottom', 'so', 'when', 'much', 'may', 'rather', 'otherwise', 'meanwhile', 'whenever', 'even', \"'s\", '‘m', 'how', 'still', 'becoming', 'did', 'at', 'do', \"n't\", \"'d\", 'done', 'ourselves', 'yourselves', 'between', 'very', 'are', 'as', 'keep', '’re', 'be', 'around', 'beforehand', 'see', 'whereupon', 'side', 'than', 'too', 'since', 'your', 'sixty', 'up', 're', '’ve', 'hereby', 'n‘t', 'here', 'nobody', 'alone', 'thence', 'it', 'yours', 'until', 'an', 'neither', 'their', 'thereafter', 'but', 'make', 'by', 'nothing', 'the', 'six', 'third', 'will', 'elsewhere', 'must', 'top', 'perhaps', 'everything', 'had', 'if', 'into', 'its', 'well', 'of', 'same', 'something', 'hundred', 'yourself', 'himself', 'none', 'on', 'would', 'regarding', 'toward', 'again', 'latterly'}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "print(sp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.vocab['wonder'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.Defaults.stop_words.add('wonder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.vocab['wonder'].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.vocab['wonder'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
